{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "04_callbacks.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ESJRCpo4OYSc",
        "KRHiUXC_OYSu"
      ]
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQ3a9z2UOYR6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-YydhHCRr2f",
        "colab_type": "code",
        "outputId": "bbfe657c-3962-42d2-be85-e052aa9266fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 679
        }
      },
      "source": [
        "# make your Google Drive accessible\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "root_dir = \"/content/gdrive/My Drive/\"\n",
        "base_dir = root_dir + 'fastai-v3/course-v3/nbs/dl2/'\n",
        "\n",
        "# navigate to the notebooks directory for dl2\n",
        "import os\n",
        "os.chdir(base_dir)\n",
        "\n",
        "# update fastai, according to instructions at https://course.fast.ai/start_colab.html\n",
        "!curl -s https://course.fast.ai/setup/colab | bash\n",
        "    \n",
        "# install fire\n",
        "!pip install fire\n",
        "!pip install nbconvert"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "Updating fastai...\n",
            "Done.\n",
            "Collecting fire\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/69/faeaae8687f4de0f5973694d02e9d6c3eb827636a009157352d98de1129e/fire-0.2.1.tar.gz (76kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 11.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from fire) (1.12.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from fire) (1.1.0)\n",
            "Building wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.2.1-py2.py3-none-any.whl size=103527 sha256=5d9ed0e939f1b931255a68b30c5afb74699d64d008ed46c4d33b5ac4f9a3b9a4\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/9c/c0/07b6dc7faf1844bb4688f46b569efe6cafaa2179c95db821da\n",
            "Successfully built fire\n",
            "Installing collected packages: fire\n",
            "Successfully installed fire-0.2.1\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (5.6.1)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbconvert) (4.6.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert) (1.4.2)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert) (0.4.4)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert) (0.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert) (3.1.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert) (0.8.4)\n",
            "Requirement already satisfied: nbformat>=4.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert) (4.4.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert) (4.3.3)\n",
            "Requirement already satisfied: jinja2>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert) (2.10.3)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from nbconvert) (2.1.3)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert) (0.6.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert) (1.12.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert) (0.5.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.4->nbconvert) (0.2.0)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.4->nbconvert) (2.6.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->nbconvert) (4.4.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.4->nbconvert) (1.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rntkPLJjOYSB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "from exp.nb_03 import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lepBc3WsOYSF",
        "colab_type": "text"
      },
      "source": [
        "## DataBunch/Learner"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOCfKdxnOYSH",
        "colab_type": "text"
      },
      "source": [
        "[Jump_to lesson 9 video](https://course.fast.ai/videos/?lesson=9&t=4799)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DdAOhTvOYSI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train,y_train,x_valid,y_valid = get_data()\n",
        "train_ds,valid_ds = Dataset(x_train, y_train),Dataset(x_valid, y_valid)\n",
        "nh,bs = 50,64\n",
        "c = y_train.max().item()+1\n",
        "loss_func = F.cross_entropy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cwn9FtXcOYSK",
        "colab_type": "text"
      },
      "source": [
        "Factor out the connected pieces of info out of the fit() argument list\n",
        "\n",
        "`fit(epochs, model, loss_func, opt, train_dl, valid_dl)`\n",
        "\n",
        "Let's replace it with something that looks like this:\n",
        "\n",
        "`fit(1, learn)`\n",
        "\n",
        "This will allow us to tweak what's happening inside the training loop in other places of the code because the `Learner` object will be mutable, so changing any of its attribute elsewhere will be seen in our training loop."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7Y0Rc3GOYSL",
        "colab_type": "text"
      },
      "source": [
        "[Jump_to lesson 9 video](https://course.fast.ai/videos/?lesson=9&t=5363)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R--tC_U8OYSL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "class DataBunch():\n",
        "    def __init__(self, train_dl, valid_dl, c=None):\n",
        "        self.train_dl,self.valid_dl,self.c = train_dl,valid_dl,c\n",
        "        \n",
        "    @property\n",
        "    def train_ds(self): return self.train_dl.dataset\n",
        "        \n",
        "    @property\n",
        "    def valid_ds(self): return self.valid_dl.dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2u01oeu_OYSN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = DataBunch(*get_dls(train_ds, valid_ds, bs), c)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qg41BSDdOYSP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "def get_model(data, lr=0.5, nh=50):\n",
        "    m = data.train_ds.x.shape[1]\n",
        "    model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,data.c))\n",
        "    return model, optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "class Learner():\n",
        "    def __init__(self, model, opt, loss_func, data):\n",
        "        self.model,self.opt,self.loss_func,self.data = model,opt,loss_func,data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rydREwYjOYSQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = Learner(*get_model(data), loss_func, data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVa8N1gEOYSR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit(epochs, learn):\n",
        "    for epoch in range(epochs):\n",
        "        learn.model.train()\n",
        "        for xb,yb in learn.data.train_dl:\n",
        "            loss = learn.loss_func(learn.model(xb), yb)\n",
        "            loss.backward()\n",
        "            learn.opt.step()\n",
        "            learn.opt.zero_grad()\n",
        "\n",
        "        learn.model.eval()\n",
        "        with torch.no_grad():\n",
        "            tot_loss,tot_acc = 0.,0.\n",
        "            for xb,yb in learn.data.valid_dl:\n",
        "                pred = learn.model(xb)\n",
        "                tot_loss += learn.loss_func(pred, yb)\n",
        "                tot_acc  += accuracy (pred,yb)\n",
        "        nv = len(learn.data.valid_dl)\n",
        "        print(epoch, tot_loss/nv, tot_acc/nv)\n",
        "    return tot_loss/nv, tot_acc/nv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXeZN3foOYSS",
        "colab_type": "code",
        "outputId": "f2b66df8-e2c6-48f0-fd17-c8612b213663",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "loss,acc = fit(1, learn)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 tensor(0.2007) tensor(0.9386)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKj27ecBOYSV",
        "colab_type": "text"
      },
      "source": [
        "## CallbackHandler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfezHOnrOYSV",
        "colab_type": "text"
      },
      "source": [
        "This was our training loop (without validation) from the previous notebook, with the inner loop contents factored out:\n",
        "\n",
        "```python\n",
        "def one_batch(xb,yb):\n",
        "    pred = model(xb)\n",
        "    loss = loss_func(pred, yb)\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    opt.zero_grad()\n",
        "    \n",
        "def fit():\n",
        "    for epoch in range(epochs):\n",
        "        for b in train_dl: one_batch(*b)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n32jE3fYOYSV",
        "colab_type": "text"
      },
      "source": [
        "Add callbacks so we can remove complexity from loop, and make it flexible:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4zactbuOYSW",
        "colab_type": "text"
      },
      "source": [
        "[Jump_to lesson 9 video](https://course.fast.ai/videos/?lesson=9&t=5628)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7xo92bFOYSW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def one_batch(xb, yb, cb):\n",
        "    if not cb.begin_batch(xb,yb): return\n",
        "    loss = cb.learn.loss_func(cb.learn.model(xb), yb)\n",
        "    if not cb.after_loss(loss): return\n",
        "    loss.backward()\n",
        "    if cb.after_backward(): cb.learn.opt.step()\n",
        "    if cb.after_step(): cb.learn.opt.zero_grad()\n",
        "\n",
        "def all_batches(dl, cb):\n",
        "    for xb,yb in dl:\n",
        "        one_batch(xb, yb, cb)\n",
        "        if cb.do_stop(): return\n",
        "\n",
        "def fit(epochs, learn, cb):\n",
        "    if not cb.begin_fit(learn): return\n",
        "    for epoch in range(epochs):\n",
        "        if not cb.begin_epoch(epoch): continue\n",
        "        all_batches(learn.data.train_dl, cb)\n",
        "        \n",
        "        if cb.begin_validate():\n",
        "            with torch.no_grad(): all_batches(learn.data.valid_dl, cb)\n",
        "        if cb.do_stop() or not cb.after_epoch(): break\n",
        "    cb.after_fit()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9Lo79p5OYSX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Callback():\n",
        "    def begin_fit(self, learn):\n",
        "        self.learn = learn\n",
        "        return True\n",
        "    def after_fit(self): return True\n",
        "    def begin_epoch(self, epoch):\n",
        "        self.epoch=epoch\n",
        "        return True\n",
        "    def begin_validate(self): return True\n",
        "    def after_epoch(self): return True\n",
        "    def begin_batch(self, xb, yb):\n",
        "        self.xb,self.yb = xb,yb\n",
        "        return True\n",
        "    def after_loss(self, loss):\n",
        "        self.loss = loss\n",
        "        return True\n",
        "    def after_backward(self): return True\n",
        "    def after_step(self): return True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTYd5qXDOYSY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CallbackHandler():\n",
        "    def __init__(self,cbs=None):\n",
        "        self.cbs = cbs if cbs else []\n",
        "\n",
        "    def begin_fit(self, learn):\n",
        "        self.learn,self.in_train = learn,True\n",
        "        learn.stop = False\n",
        "        res = True\n",
        "        for cb in self.cbs: res = res and cb.begin_fit(learn)\n",
        "        return res\n",
        "\n",
        "    def after_fit(self):\n",
        "        res = not self.in_train\n",
        "        for cb in self.cbs: res = res and cb.after_fit()\n",
        "        return res\n",
        "    \n",
        "    def begin_epoch(self, epoch):\n",
        "        self.learn.model.train()\n",
        "        self.in_train=True\n",
        "        res = True\n",
        "        for cb in self.cbs: res = res and cb.begin_epoch(epoch)\n",
        "        return res\n",
        "\n",
        "    def begin_validate(self):\n",
        "        self.learn.model.eval()\n",
        "        self.in_train=False\n",
        "        res = True\n",
        "        for cb in self.cbs: res = res and cb.begin_validate()\n",
        "        return res\n",
        "\n",
        "    def after_epoch(self):\n",
        "        res = True\n",
        "        for cb in self.cbs: res = res and cb.after_epoch()\n",
        "        return res\n",
        "    \n",
        "    def begin_batch(self, xb, yb):\n",
        "        res = True\n",
        "        for cb in self.cbs: res = res and cb.begin_batch(xb, yb)\n",
        "        return res\n",
        "\n",
        "    def after_loss(self, loss):\n",
        "        res = self.in_train\n",
        "        for cb in self.cbs: res = res and cb.after_loss(loss)\n",
        "        return res\n",
        "\n",
        "    def after_backward(self):\n",
        "        res = True\n",
        "        for cb in self.cbs: res = res and cb.after_backward()\n",
        "        return res\n",
        "\n",
        "    def after_step(self):\n",
        "        res = True\n",
        "        for cb in self.cbs: res = res and cb.after_step()\n",
        "        return res\n",
        "    \n",
        "    def do_stop(self):\n",
        "        try:     return self.learn.stop\n",
        "        finally: self.learn.stop = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIddH_C9OYSZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TestCallback(Callback):\n",
        "    def begin_fit(self,learn):\n",
        "        super().begin_fit(learn)\n",
        "        self.n_iters = 0\n",
        "        return True\n",
        "        \n",
        "    def after_step(self):\n",
        "        self.n_iters += 1\n",
        "        print(self.n_iters)\n",
        "        if self.n_iters>=10: self.learn.stop = True\n",
        "        return True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtuSIxOsOYSa",
        "colab_type": "code",
        "outputId": "0cdadc01-fba9-4d17-bb0f-d5efd42884ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "source": [
        "fit(1, learn, cb=CallbackHandler([TestCallback()]))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ygrk57qcOYSb",
        "colab_type": "text"
      },
      "source": [
        "This is roughly how fastai does it now (except that the handler can also change and return `xb`, `yb`, and `loss`). But let's see if we can make things simpler and more flexible, so that a single class has access to everything and can change anything at any time. The fact that we're passing `cb` to so many functions is a strong hint they should all be in the same class!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESJRCpo4OYSc",
        "colab_type": "text"
      },
      "source": [
        "## Runner"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8J-tkLwAOYSc",
        "colab_type": "text"
      },
      "source": [
        "[Jump_to lesson 9 video](https://course.fast.ai/videos/?lesson=9&t=5811)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBJPD40YOYSc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "import re\n",
        "\n",
        "_camel_re1 = re.compile('(.)([A-Z][a-z]+)')\n",
        "_camel_re2 = re.compile('([a-z0-9])([A-Z])')\n",
        "def camel2snake(name):\n",
        "    s1 = re.sub(_camel_re1, r'\\1_\\2', name)\n",
        "    return re.sub(_camel_re2, r'\\1_\\2', s1).lower()\n",
        "\n",
        "class Callback():\n",
        "    _order=0\n",
        "    def set_runner(self, run): self.run=run\n",
        "    def __getattr__(self, k): return getattr(self.run, k)\n",
        "    @property\n",
        "    def name(self):\n",
        "        name = re.sub(r'Callback$', '', self.__class__.__name__)\n",
        "        return camel2snake(name or 'callback')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LTnUiksOYSd",
        "colab_type": "text"
      },
      "source": [
        "This first callback is reponsible to switch the model back and forth in training or validation mode, as well as maintaining a count of the iterations, or the percentage of iterations ellapsed in the epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-4lhJ9fOYSd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "class TrainEvalCallback(Callback):\n",
        "    def begin_fit(self):\n",
        "        self.run.n_epochs=0.\n",
        "        self.run.n_iter=0\n",
        "    \n",
        "    def after_batch(self):\n",
        "        if not self.in_train: return\n",
        "        self.run.n_epochs += 1./self.iters\n",
        "        self.run.n_iter   += 1\n",
        "        \n",
        "    def begin_epoch(self):\n",
        "        self.run.n_epochs=self.epoch\n",
        "        self.model.train()\n",
        "        self.run.in_train=True\n",
        "\n",
        "    def begin_validate(self):\n",
        "        self.model.eval()\n",
        "        self.run.in_train=False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFCOD2UwOYSe",
        "colab_type": "text"
      },
      "source": [
        "We'll also re-create our TestCallback"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcSN7wYfOYSf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TestCallback(Callback):\n",
        "    def after_step(self):\n",
        "        if self.train_eval.n_iters>=10: return True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaHlrDK0OYSg",
        "colab_type": "code",
        "outputId": "d25cf6d6-273a-49eb-9cf4-c34ebd5f51e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "cbname = 'TrainEvalCallback'\n",
        "camel2snake(cbname)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'train_eval_callback'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdXtNcDqOYSh",
        "colab_type": "code",
        "outputId": "455e9914-f94f-46aa-bc7b-dd1488e2b8dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "TrainEvalCallback().name"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'train_eval'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CH16pb6OYSi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "from typing import *\n",
        "\n",
        "def listify(o):\n",
        "    if o is None: return []\n",
        "    if isinstance(o, list): return o\n",
        "    if isinstance(o, str): return [o]\n",
        "    if isinstance(o, Iterable): return list(o)\n",
        "    return [o]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxmzFnc8OYSj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "class Runner():\n",
        "    def __init__(self, cbs=None, cb_funcs=None):\n",
        "        cbs = listify(cbs)\n",
        "        for cbf in listify(cb_funcs):\n",
        "            cb = cbf()\n",
        "            setattr(self, cb.name, cb)\n",
        "            cbs.append(cb)\n",
        "        self.stop,self.cbs = False,[TrainEvalCallback()]+cbs\n",
        "\n",
        "    @property\n",
        "    def opt(self):       return self.learn.opt\n",
        "    @property\n",
        "    def model(self):     return self.learn.model\n",
        "    @property\n",
        "    def loss_func(self): return self.learn.loss_func\n",
        "    @property\n",
        "    def data(self):      return self.learn.data\n",
        "\n",
        "    def one_batch(self, xb, yb):\n",
        "        self.xb,self.yb = xb,yb\n",
        "        if self('begin_batch'): return\n",
        "        self.pred = self.model(self.xb)\n",
        "        if self('after_pred'): return\n",
        "        self.loss = self.loss_func(self.pred, self.yb)\n",
        "        if self('after_loss') or not self.in_train: return\n",
        "        self.loss.backward()\n",
        "        if self('after_backward'): return\n",
        "        self.opt.step()\n",
        "        if self('after_step'): return\n",
        "        self.opt.zero_grad()\n",
        "\n",
        "    def all_batches(self, dl):\n",
        "        self.iters = len(dl)\n",
        "        for xb,yb in dl:\n",
        "            if self.stop: break\n",
        "            self.one_batch(xb, yb)\n",
        "            self('after_batch')\n",
        "        self.stop=False\n",
        "\n",
        "    def fit(self, epochs, learn):\n",
        "        self.epochs,self.learn = epochs,learn\n",
        "\n",
        "        try:\n",
        "            for cb in self.cbs: cb.set_runner(self)\n",
        "            if self('begin_fit'): return\n",
        "            for epoch in range(epochs):\n",
        "                self.epoch = epoch\n",
        "                if not self('begin_epoch'): self.all_batches(self.data.train_dl)\n",
        "\n",
        "                with torch.no_grad(): \n",
        "                    if not self('begin_validate'): self.all_batches(self.data.valid_dl)\n",
        "                if self('after_epoch'): break\n",
        "            \n",
        "        finally:\n",
        "            self('after_fit')\n",
        "            self.learn = None\n",
        "\n",
        "    def __call__(self, cb_name):\n",
        "        for cb in sorted(self.cbs, key=lambda x: x._order):\n",
        "            f = getattr(cb, cb_name, None)\n",
        "            if f and f(): return True\n",
        "        return False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHCvCUedOYSk",
        "colab_type": "text"
      },
      "source": [
        "Third callback: how to compute metrics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T079rUacOYSl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "class AvgStats():\n",
        "    def __init__(self, metrics, in_train): self.metrics,self.in_train = listify(metrics),in_train\n",
        "    \n",
        "    def reset(self):\n",
        "        self.tot_loss,self.count = 0.,0\n",
        "        self.tot_mets = [0.] * len(self.metrics)\n",
        "        \n",
        "    @property\n",
        "    def all_stats(self): return [self.tot_loss.item()] + self.tot_mets\n",
        "    @property\n",
        "    def avg_stats(self): return [o/self.count for o in self.all_stats]\n",
        "    \n",
        "    def __repr__(self):\n",
        "        if not self.count: return \"\"\n",
        "        return f\"{'train' if self.in_train else 'valid'}: {self.avg_stats}\"\n",
        "\n",
        "    def accumulate(self, run):\n",
        "        bn = run.xb.shape[0]\n",
        "        self.tot_loss += run.loss * bn\n",
        "        self.count += bn\n",
        "        for i,m in enumerate(self.metrics):\n",
        "            self.tot_mets[i] += m(run.pred, run.yb) * bn\n",
        "\n",
        "class AvgStatsCallback(Callback):\n",
        "    def __init__(self, metrics):\n",
        "        self.train_stats,self.valid_stats = AvgStats(metrics,True),AvgStats(metrics,False)\n",
        "        \n",
        "    def begin_epoch(self):\n",
        "        self.train_stats.reset()\n",
        "        self.valid_stats.reset()\n",
        "        \n",
        "    def after_loss(self):\n",
        "        stats = self.train_stats if self.in_train else self.valid_stats\n",
        "        with torch.no_grad(): stats.accumulate(self.run)\n",
        "    \n",
        "    def after_epoch(self):\n",
        "        print(self.train_stats)\n",
        "        print(self.valid_stats)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZpj7493OYSn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = Learner(*get_model(data), loss_func, data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDZdMz2nOYSn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stats = AvgStatsCallback([accuracy])\n",
        "run = Runner(cbs=stats)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwnse2WpOYSo",
        "colab_type": "code",
        "outputId": "09ae40a3-8b9d-4395-c57d-246835c82c42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "run.fit(2, learn)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train: [0.3281544921875, tensor(0.8994)]\n",
            "valid: [0.17265968017578126, tensor(0.9502)]\n",
            "train: [0.14961525390625, tensor(0.9543)]\n",
            "valid: [0.2286132080078125, tensor(0.9283)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGyr8BK7OYSp",
        "colab_type": "code",
        "outputId": "fefffd03-8daf-4585-e615-b0d6abc34ee8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "loss,acc = stats.valid_stats.avg_stats\n",
        "assert acc>0.9\n",
        "loss,acc"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.2286132080078125, tensor(0.9283))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74GXWrjcOYSq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "from functools import partial"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6-mylvmOYSq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc_cbf = partial(AvgStatsCallback,accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSrZYRwqOYSr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "run = Runner(cb_funcs=acc_cbf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-ddq-FaOYSr",
        "colab_type": "code",
        "outputId": "427154f5-c960-4304-e5d1-ace00ec4a64f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "run.fit(1, learn)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train: [0.114884501953125, tensor(0.9644)]\n",
            "valid: [0.1125452880859375, tensor(0.9670)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yokga8W0OYSs",
        "colab_type": "text"
      },
      "source": [
        "Using Jupyter means we can get tab-completion even for dynamic code like this! :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9U4DxS_ROYSt",
        "colab_type": "code",
        "outputId": "580133e9-edf1-4460-8e10-5f801c47ce93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "run.avg_stats.valid_stats.avg_stats"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.1125452880859375, tensor(0.9670)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRHiUXC_OYSu",
        "colab_type": "text"
      },
      "source": [
        "## Export"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvzLhDMxOYSu",
        "colab_type": "code",
        "outputId": "79083c61-6d97-473c-a9ae-de454b136e09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "!python notebook2script.py 04_callbacks.ipynb"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Converted 04_callbacks.ipynb to exp/nb_04.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5L2RTk4SOYSv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}