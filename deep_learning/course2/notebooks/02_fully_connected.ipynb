{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "02_fully_connected.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "jtzkbk8T4qNI",
        "1Om89usI4qNz",
        "MlMjt36f4qO-",
        "gCBM6RvJ4qPe",
        "kFS87FlG4qQG",
        "8QNqMVUy4qQe"
      ]
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ix9vgD1Z4qH8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25rbMohV49U2",
        "colab_type": "code",
        "outputId": "988e9020-149e-4e3d-f93c-dc3e8470d9f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        }
      },
      "source": [
        "# make your Google Drive accessible\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "root_dir = \"/content/gdrive/My Drive/\"\n",
        "base_dir = root_dir + 'fastai-v3/course-v3/nbs/dl2/'\n",
        "\n",
        "# navigate to the notebooks directory for dl2\n",
        "import os\n",
        "os.chdir(base_dir)\n",
        "\n",
        "# update fastai, according to instructions at https://course.fast.ai/start_colab.html\n",
        "!curl -s https://course.fast.ai/setup/colab | bash\n",
        "    \n",
        "# install fire\n",
        "!pip install fire\n",
        "!pip install nbconvert"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "Updating fastai...\n",
            "Done.\n",
            "Collecting fire\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/69/faeaae8687f4de0f5973694d02e9d6c3eb827636a009157352d98de1129e/fire-0.2.1.tar.gz (76kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 3.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from fire) (1.12.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from fire) (1.1.0)\n",
            "Building wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.2.1-py2.py3-none-any.whl size=103527 sha256=d00eb5b70253c21c4b1acba844a6954cda6a2cfa8c174e513df733f4361f98ca\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/9c/c0/07b6dc7faf1844bb4688f46b569efe6cafaa2179c95db821da\n",
            "Successfully built fire\n",
            "Installing collected packages: fire\n",
            "Successfully installed fire-0.2.1\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (5.6.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert) (1.4.2)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert) (0.3)\n",
            "Requirement already satisfied: nbformat>=4.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert) (4.4.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert) (4.3.2)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert) (0.8.4)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbconvert) (4.5.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert) (3.1.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from nbconvert) (2.1.3)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert) (0.6.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert) (0.4.2)\n",
            "Requirement already satisfied: jinja2>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert) (2.10.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.4->nbconvert) (0.2.0)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.4->nbconvert) (2.6.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->nbconvert) (4.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->nbconvert) (1.12.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert) (0.5.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.4->nbconvert) (1.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaUmMAaA4qIO",
        "colab_type": "text"
      },
      "source": [
        "## The forward and backward passes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-sHkDvS4qIY",
        "colab_type": "text"
      },
      "source": [
        "[Jump_to lesson 8 video](https://course.fast.ai/videos/?lesson=8&t=4960)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_B_iW0-f4qIb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "from exp.nb_01 import *\n",
        "\n",
        "def get_data():\n",
        "    path = datasets.download_data(MNIST_URL, ext='.gz')\n",
        "    with gzip.open(path, 'rb') as f:\n",
        "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n",
        "    return map(tensor, (x_train,y_train,x_valid,y_valid))\n",
        "\n",
        "def normalize(x, m, s): return (x-m)/s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjSmf1z55QSH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, y_train, x_valid, y_valid = get_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAcKczLPSJ4N",
        "colab_type": "text"
      },
      "source": [
        "Mean is not 0 and std is not 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Re7noZ_4qIl",
        "colab_type": "code",
        "outputId": "1114e010-b93e-4d56-a453-4d4a322a0b96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        }
      },
      "source": [
        "train_mean, train_std = x_train.mean(), x_train.std()\n",
        "train_mean, train_std"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1304), tensor(0.3073))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZ_fuk0sSNsE",
        "colab_type": "text"
      },
      "source": [
        "Hence we normalize them"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdBOgtfJ4qIw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = normalize(x_train, train_mean, train_std)\n",
        "x_valid = normalize(x_valid, train_mean, train_std)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBTbIo-FSY8k",
        "colab_type": "text"
      },
      "source": [
        "Note that we do not normalize the validation set with its own mean and std because then the training and the validation sets will be on different scales"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDVS-OfySimi",
        "colab_type": "code",
        "outputId": "1aad52ea-d289-4884-afc4-9f68ca5caa51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        }
      },
      "source": [
        "train_mean, train_std = x_train.mean(), x_train.std()\n",
        "train_mean, train_std"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.0001), tensor(1.))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46_631zZ4qJP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "def test_near_zero(a,tol=1e-3): assert a.abs()<tol, f\"Near zero: {a}\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnBxhRiL4qJa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near_zero(x_train.mean())\n",
        "test_near_zero(1-x_train.std())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boFih_q7Su3C",
        "colab_type": "code",
        "outputId": "e03ac73e-5d28-4536-ef7e-3166d9b5be43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        }
      },
      "source": [
        "n,m = x_train.shape\n",
        "c = y_train.max() + 1\n",
        "n,m,c"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 784, tensor(10))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2ZGb4pq4qJw",
        "colab_type": "text"
      },
      "source": [
        "## Foundations version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAcRavzx4qJ0",
        "colab_type": "text"
      },
      "source": [
        "### Basic architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLFyMFQwTM1-",
        "colab_type": "text"
      },
      "source": [
        "Just to simplify things we will use mse as our error function instead of cross entropy and 1 activation as our output instead of 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09dpfxUL4qJ2",
        "colab_type": "text"
      },
      "source": [
        "[Jump_to lesson 8 video](https://course.fast.ai/videos/?lesson=8&t=5128)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stHf9sFtTh8g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nh = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXzKXsziTiBu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w1 = torch.randn(m, nh)\n",
        "b1 = torch.zeros(nh)\n",
        "w2 = torch.randn(nh, 1)\n",
        "b2 = torch.randn(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQxeah5V4qKC",
        "colab_type": "text"
      },
      "source": [
        "[Tinker practice](https://course.fast.ai/videos/?lesson=8&t=5255)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b65mY-wXVLPo",
        "colab_type": "text"
      },
      "source": [
        "Numbers with mean 0 and std 1 / root(inp) will give an output that has mean 0 and std 1. Write about fixup initialization in article"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRe4Vyap4qKV",
        "colab_type": "code",
        "outputId": "55f91fb7-ba78-4086-dbc3-d584ff22fe3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        }
      },
      "source": [
        "# This should be ~ (0,1) (mean,std)...\n",
        "x_valid.mean(),x_valid.std()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(-0.0057), tensor(0.9924))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwH1iImg4qKe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lin(x, w, b): return x@w + b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFnlxzMi4qKk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t = lin(x_valid, w1, b1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Az58yGzr4qKu",
        "colab_type": "code",
        "outputId": "b6de0807-4651-4444-e41e-99e1c03fac83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        }
      },
      "source": [
        "#...so should this, because we used kaiming init, which is designed to do this\n",
        "t.mean(),t.std()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(1.1935), tensor(27.7240))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGNIqUIkURn5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# simplified version of kaiming init\n",
        "w1 = torch.randn(m,nh)/math.sqrt(m)\n",
        "b1 = torch.zeros(nh)\n",
        "w2 = torch.randn(nh,1)/math.sqrt(nh)\n",
        "b2 = torch.zeros(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_kRY52vxPYn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t = lin(x_valid, w1, b1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2yoxiCkxQDb",
        "colab_type": "code",
        "outputId": "f9689d33-e25b-4252-eb89-127d28ace9bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        }
      },
      "source": [
        "t.mean(),t.std()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.0565), tensor(1.0197))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ddh2YLORxH2s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# after kaiming init\n",
        "test_near_zero(w1.mean())\n",
        "test_near_zero(w1.std()-1/math.sqrt(m))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4Yl0G7DV05X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def relu(x): return x.clamp_min(0.)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzLx-Do04qK0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t = relu(lin(x_valid, w1, b1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyNC_73e4qK-",
        "colab_type": "code",
        "outputId": "b0813784-3cbc-47d8-faf1-a8edbdc06d75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        }
      },
      "source": [
        "t.mean(), t.std()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.4314), tensor(0.6375))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDvLZ_P34qLL",
        "colab_type": "text"
      },
      "source": [
        "From pytorch docs: `a: the negative slope of the rectifier used after this layer (0 for ReLU by default)`\n",
        "\n",
        "$$\\text{std} = \\sqrt{\\frac{2}{(1 + a^2) \\times \\text{fan_in}}}$$\n",
        "\n",
        "This was introduced in the paper that described the Imagenet-winning approach from *He et al*: [Delving Deep into Rectifiers](https://arxiv.org/abs/1502.01852), which was also the first paper that claimed \"super-human performance\" on Imagenet (and, most importantly, it introduced resnets!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3hee75Y4qLQ",
        "colab_type": "text"
      },
      "source": [
        "[Jump_to lesson 8 video](https://course.fast.ai/videos/?lesson=8&t=5128)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xA1KO5AlU_-5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w1 = torch.randn(m, nh) * math.sqrt(2/m)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzK-wzhl4qLR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# kaiming init / he init for relu\n",
        "w1 = torch.randn(m,nh)*math.sqrt(2/m)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FW4t-XIq4qLW",
        "colab_type": "code",
        "outputId": "ab6308e5-a34a-4554-daf2-9b51a2be25df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        }
      },
      "source": [
        "w1.mean(),w1.std()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(-0.0004), tensor(0.0504))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5l71lZl4qLg",
        "colab_type": "code",
        "outputId": "3d8f19f7-0520-4e27-a7b5-e37803ccd84c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        }
      },
      "source": [
        "t = relu(lin(x_valid, w1, b1))\n",
        "t.mean(),t.std()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.5452), tensor(0.8337))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LN7DMiS24qLn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "from torch.nn import init"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTYRcZ3oWoR-",
        "colab_type": "text"
      },
      "source": [
        "Fan out means do you want to preserve the variance in the forward or the backward pass. If we divide by m i.e. input, it'll preserve in the forward pass and if we divide by nh i.e. output it'll preserve in the backward pass"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxEU5KOf4qLs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w1 = torch.zeros(m,nh)\n",
        "init.kaiming_normal_(w1, mode='fan_out')\n",
        "t = relu(lin(x_valid, w1, b1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-0w-SvU4qL0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "init.kaiming_normal_??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcCWkzzJ4qL4",
        "colab_type": "code",
        "outputId": "f6682826-bdda-4f45-be38-1252b397724b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        }
      },
      "source": [
        "w1.mean(),w1.std()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(-0.0003), tensor(0.0503))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8N5lBFr4qMA",
        "colab_type": "code",
        "outputId": "ae3769d5-d2db-49f5-91d0-58ad34dee4e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        }
      },
      "source": [
        "t.mean(),t.std()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.5252), tensor(0.7879))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CaPsbKk4qMJ",
        "colab_type": "code",
        "outputId": "781390bc-c400-49d0-c42c-3cf3d538f38d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        }
      },
      "source": [
        "w1.shape"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([784, 50])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__HfRYAJ4qMP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dILde8C4qMV",
        "colab_type": "code",
        "outputId": "97ad9040-50db-4cfe-ce2a-0c7d017790e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        }
      },
      "source": [
        "torch.nn.Linear(m,nh).weight.shape"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50, 784])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhTa00H64qMb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.nn.Linear.forward??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pie3JHnX4qMf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.nn.functional.linear??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoYAEaSy4qMk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.nn.Conv2d??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPyQklRF4qMp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.nn.modules.conv._ConvNd.reset_parameters??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeeIlVLI4qMt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# what if...?\n",
        "def relu(x): return x.clamp_min(0.) - 0.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yRxDcoA4qMx",
        "colab_type": "code",
        "outputId": "5a2d7f12-5a47-409f-83e4-8407c99e95d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        }
      },
      "source": [
        "# kaiming init / he init for relu\n",
        "w1 = torch.randn(m,nh)*math.sqrt(2./m )\n",
        "t1 = relu(lin(x_valid, w1, b1))\n",
        "t1.mean(),t1.std()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.0149), tensor(0.7597))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Donp2UZL4qM2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model(xb):\n",
        "    l1 = lin(xb, w1, b1)\n",
        "    l2 = relu(l1)\n",
        "    l3 = lin(l2, w2, b2)\n",
        "    return l3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1h5GL0jx-vF",
        "colab_type": "code",
        "outputId": "ae8dcedf-f2a8-4e68-852a-e7abd93c5e11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        }
      },
      "source": [
        "t3 = model(x_valid)\n",
        "t3.mean(), t3.std()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1807), tensor(0.6239))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNIhqt9f4qM7",
        "colab_type": "code",
        "outputId": "193eb689-bb47-43f9-c7c7-49d0902a8a2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 96
        }
      },
      "source": [
        "%timeit -n 10 _=model(x_valid)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10 loops, best of 3: 20.7 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njhF-fH_4qNB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert model(x_valid).shape==torch.Size([x_valid.shape[0],1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtzkbk8T4qNI",
        "colab_type": "text"
      },
      "source": [
        "### Loss function: MSE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzkHAlb54qNM",
        "colab_type": "text"
      },
      "source": [
        "[Jump_to lesson 8 video](https://course.fast.ai/videos/?lesson=8&t=6372)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nuViHym4qNO",
        "colab_type": "code",
        "outputId": "6bb283e7-5bf6-4b44-f948-893a02acdbe8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "model(x_valid).shape"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10000, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZF9PGiK4qNS",
        "colab_type": "text"
      },
      "source": [
        "We need `squeeze()` to get rid of that trailing (,1), in order to use `mse`. (Of course, `mse` is not a suitable loss function for multi-class classification; we'll use a better loss function soon. We'll use `mse` for now to keep things simple.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVpKTtv44qNX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "def mse(output, targ): return (output.squeeze(-1) - targ).pow(2).mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnA9l_5JiBLx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train, y_valid = y_train.float(), y_valid.float()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Im8PDogfiGeS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds = model(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CW760txX4qNh",
        "colab_type": "code",
        "outputId": "8f9f59fb-5f7a-43d4-dd7c-6325f1a35e91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "preds.shape"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50000, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74zX_XT14qNm",
        "colab_type": "code",
        "outputId": "e68ee5ef-27ff-4db1-8e0a-8438719312eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "mse(preds, y_train)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(26.5406)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Om89usI4qNz",
        "colab_type": "text"
      },
      "source": [
        "### Gradients and backward pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qGP1DU44qN0",
        "colab_type": "text"
      },
      "source": [
        "[Jump_to lesson 8 video](https://course.fast.ai/videos/?lesson=8&t=6493)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXfeIk-W4qN1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mse_grad(inp, targ): \n",
        "    # grad of loss with respect to output of previous layer\n",
        "    inp.g = 2. * (inp.squeeze() - targ).unsqueeze(-1) / inp.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Prhm7jpx4qN6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def relu_grad(inp, out):\n",
        "    # grad of relu with respect to input activations\n",
        "    inp.g = (inp>0).float() * out.g"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etKq8xWa4qN9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lin_grad(inp, out, w, b):\n",
        "    # grad of matmul with respect to input\n",
        "    inp.g = out.g @ w.t()\n",
        "    w.g = (inp.unsqueeze(-1) * out.g.unsqueeze(1)).sum(0)\n",
        "    b.g = out.g.sum(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nnbn-au4qOU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward_and_backward(inp, targ):\n",
        "    # forward pass:\n",
        "    l1 = inp @ w1 + b1\n",
        "    l2 = relu(l1)\n",
        "    out = l2 @ w2 + b2\n",
        "    # we don't actually need the loss in backward!\n",
        "    loss = mse(out, targ)\n",
        "    \n",
        "    # backward pass:\n",
        "    mse_grad(out, targ)\n",
        "    lin_grad(l2, out, w2, b2)\n",
        "    relu_grad(l1, l2)\n",
        "    lin_grad(inp, l1, w1, b1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruHdJ9gN4qOY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "forward_and_backward(x_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzAD1Zyx4qOc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save for testing against later\n",
        "w1g = w1.g.clone()\n",
        "w2g = w2.g.clone()\n",
        "b1g = b1.g.clone()\n",
        "b2g = b2.g.clone()\n",
        "ig  = x_train.g.clone()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xZfLD1P4qOg",
        "colab_type": "text"
      },
      "source": [
        "We cheat a little bit and use PyTorch autograd to check our results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQ0fMZee4qOh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xt2 = x_train.clone().requires_grad_(True)\n",
        "w12 = w1.clone().requires_grad_(True)\n",
        "w22 = w2.clone().requires_grad_(True)\n",
        "b12 = b1.clone().requires_grad_(True)\n",
        "b22 = b2.clone().requires_grad_(True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZDV4U1r4qOl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward(inp, targ):\n",
        "    # forward pass:\n",
        "    l1 = inp @ w12 + b12\n",
        "    l2 = relu(l1)\n",
        "    out = l2 @ w22 + b22\n",
        "    # we don't actually need the loss in backward!\n",
        "    return mse(out, targ)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycmTh0HC4qOx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = forward(xt2, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgthpxxv4qO1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clqorbFx4qO6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near(w22.grad, w2g)\n",
        "test_near(b22.grad, b2g)\n",
        "test_near(w12.grad, w1g)\n",
        "test_near(b12.grad, b1g)\n",
        "test_near(xt2.grad, ig )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXwHdBqj4qO9",
        "colab_type": "text"
      },
      "source": [
        "## Refactor model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlMjt36f4qO-",
        "colab_type": "text"
      },
      "source": [
        "### Layers as classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcpHf10s4qO_",
        "colab_type": "text"
      },
      "source": [
        "[Jump_to lesson 8 video](https://course.fast.ai/videos/?lesson=8&t=7112)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUDtAC2K4qPA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Relu():\n",
        "    def __call__(self, inp):\n",
        "        self.inp = inp\n",
        "        self.out = inp.clamp_min(0.)-0.5\n",
        "        return self.out\n",
        "    \n",
        "    def backward(self): self.inp.g = (self.inp>0).float() * self.out.g"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Q6TEYZq4qPE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Lin():\n",
        "    def __init__(self, w, b): self.w,self.b = w,b\n",
        "        \n",
        "    def __call__(self, inp):\n",
        "        self.inp = inp\n",
        "        self.out = inp@self.w + self.b\n",
        "        return self.out\n",
        "    \n",
        "    def backward(self):\n",
        "        self.inp.g = self.out.g @ self.w.t()\n",
        "        # Creating a giant outer product, just to sum it, is inefficient!\n",
        "        self.w.g = (self.inp.unsqueeze(-1) * self.out.g.unsqueeze(1)).sum(0)\n",
        "        self.b.g = self.out.g.sum(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7Y12eLp4qPI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Mse():\n",
        "    def __call__(self, inp, targ):\n",
        "        self.inp = inp\n",
        "        self.targ = targ\n",
        "        self.out = (inp.squeeze() - targ).pow(2).mean()\n",
        "        return self.out\n",
        "    \n",
        "    def backward(self):\n",
        "        self.inp.g = 2. * (self.inp.squeeze() - self.targ).unsqueeze(-1) / self.targ.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p43qFgvA4qPL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model():\n",
        "    def __init__(self, w1, b1, w2, b2):\n",
        "        self.layers = [Lin(w1,b1), Relu(), Lin(w2,b2)]\n",
        "        self.loss = Mse()\n",
        "        \n",
        "    def __call__(self, x, targ):\n",
        "        for l in self.layers: x = l(x)\n",
        "        return self.loss(x, targ)\n",
        "    \n",
        "    def backward(self):\n",
        "        self.loss.backward()\n",
        "        for l in reversed(self.layers): l.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKYJsaPm4qPO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w1.g,b1.g,w2.g,b2.g = [None]*4\n",
        "model = Model(w1, b1, w2, b2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFIhNTIF4qPR",
        "colab_type": "code",
        "outputId": "ebe5b6c5-e5b0-44d3-e024-ec91404e2d11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "%time loss = model(x_train, y_train)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 121 ms, sys: 0 ns, total: 121 ms\n",
            "Wall time: 126 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuY26-cC4qPX",
        "colab_type": "code",
        "outputId": "276478d3-b9f8-43c3-f1b6-a2d4bccbbb81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "%time model.backward()"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3.46 s, sys: 3.63 s, total: 7.08 s\n",
            "Wall time: 7.15 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqW1W0vN4qPb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near(w2g, w2.g)\n",
        "test_near(b2g, b2.g)\n",
        "test_near(w1g, w1.g)\n",
        "test_near(b1g, b1.g)\n",
        "test_near(ig, x_train.g)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xboc8iFgcoJP",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCBM6RvJ4qPe",
        "colab_type": "text"
      },
      "source": [
        "### Module.forward()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cLh1UuY4qPf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Module():\n",
        "    def __call__(self, *args):\n",
        "        self.args = args\n",
        "        self.out = self.forward(*args)\n",
        "        return self.out\n",
        "    \n",
        "    def forward(self): raise Exception('not implemented')\n",
        "    def backward(self): self.bwd(self.out, *self.args)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2L1jbLj4qPj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Relu(Module):\n",
        "    def forward(self, inp): return inp.clamp_min(0.)-0.5\n",
        "    def bwd(self, out, inp): inp.g = (inp>0).float() * out.g"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3TDjzRE4qPo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Lin(Module):\n",
        "    def __init__(self, w, b): self.w,self.b = w,b\n",
        "        \n",
        "    def forward(self, inp): return inp@self.w + self.b\n",
        "    \n",
        "    def bwd(self, out, inp):\n",
        "        inp.g = out.g @ self.w.t()\n",
        "        self.w.g = torch.einsum(\"bi,bj->ij\", inp, out.g)\n",
        "        self.b.g = out.g.sum(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meCp6dHy4qPs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Mse(Module):\n",
        "    def forward (self, inp, targ): return (inp.squeeze() - targ).pow(2).mean()\n",
        "    def bwd(self, out, inp, targ): inp.g = 2*(inp.squeeze()-targ).unsqueeze(-1) / targ.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjaNSP4t4qPu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model():\n",
        "    def __init__(self):\n",
        "        self.layers = [Lin(w1,b1), Relu(), Lin(w2,b2)]\n",
        "        self.loss = Mse()\n",
        "        \n",
        "    def __call__(self, x, targ):\n",
        "        for l in self.layers: x = l(x)\n",
        "        return self.loss(x, targ)\n",
        "    \n",
        "    def backward(self):\n",
        "        self.loss.backward()\n",
        "        for l in reversed(self.layers): l.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnrJtbwc4qPx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w1.g,b1.g,w2.g,b2.g = [None]*4\n",
        "model = Model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDaGjcuH4qP0",
        "colab_type": "code",
        "outputId": "29b36015-b12c-46d4-837f-bd719104bf47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "%time loss = model(x_train, y_train)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 117 ms, sys: 1.56 ms, total: 118 ms\n",
            "Wall time: 119 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwUp3nLZ4qP8",
        "colab_type": "code",
        "outputId": "2520f8b4-5b8c-4fe5-acf4-9b40499fe42d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "%time model.backward()"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 245 ms, sys: 16.2 ms, total: 262 ms\n",
            "Wall time: 283 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beotx3eS4qQC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near(w2g, w2.g)\n",
        "test_near(b2g, b2.g)\n",
        "test_near(w1g, w1.g)\n",
        "test_near(b1g, b1.g)\n",
        "test_near(ig, x_train.g)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFS87FlG4qQG",
        "colab_type": "text"
      },
      "source": [
        "### Without einsum"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ai-JaFFN4qQH",
        "colab_type": "text"
      },
      "source": [
        "[Jump_to lesson 8 video](https://course.fast.ai/videos/?lesson=8&t=7484)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlJq_1_b4qQI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Lin(Module):\n",
        "    def __init__(self, w, b): self.w,self.b = w,b\n",
        "        \n",
        "    def forward(self, inp): return inp@self.w + self.b\n",
        "    \n",
        "    def bwd(self, out, inp):\n",
        "        inp.g = out.g @ self.w.t()\n",
        "        self.w.g = inp.t() @ out.g\n",
        "        self.b.g = out.g.sum(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tjhE5g94qQL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w1.g,b1.g,w2.g,b2.g = [None]*4\n",
        "model = Model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g12oy52A4qQP",
        "colab_type": "code",
        "outputId": "130f401b-e0c6-4506-f9de-2514b93d8cab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "%time loss = model(x_train, y_train)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 109 ms, sys: 0 ns, total: 109 ms\n",
            "Wall time: 110 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJALxE4i4qQR",
        "colab_type": "code",
        "outputId": "1d2e59d2-90b4-4b57-d45a-864f694389b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "%time model.backward()"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 235 ms, sys: 6.88 ms, total: 242 ms\n",
            "Wall time: 247 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FU_hYFhb4qQV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near(w2g, w2.g)\n",
        "test_near(b2g, b2.g)\n",
        "test_near(w1g, w1.g)\n",
        "test_near(b1g, b1.g)\n",
        "test_near(ig, x_train.g)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QNqMVUy4qQe",
        "colab_type": "text"
      },
      "source": [
        "### nn.Linear and nn.Module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ratDnk44qQh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "from torch import nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJ1_isqm4qQj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, n_in, nh, n_out):\n",
        "        super().__init__()\n",
        "        self.layers = [nn.Linear(n_in,nh), nn.ReLU(), nn.Linear(nh,n_out)]\n",
        "        self.loss = mse\n",
        "        \n",
        "    def __call__(self, x, targ):\n",
        "        for l in self.layers: x = l(x)\n",
        "        return self.loss(x.squeeze(), targ)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0g36n6GR4qQn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(m, nh, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4wV-ieO4qQp",
        "colab_type": "code",
        "outputId": "4225e1ac-59b1-4ec2-dcfa-3b6e8651d81a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "%time loss = model(x_train, y_train)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 110 ms, sys: 311 µs, total: 110 ms\n",
            "Wall time: 114 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LphOReCB4qQv",
        "colab_type": "code",
        "outputId": "2402be0d-4a89-47b6-c9d0-0a46f784fa3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "%time loss.backward()"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 95.8 ms, sys: 0 ns, total: 95.8 ms\n",
            "Wall time: 95 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBH7VW7m4qQ2",
        "colab_type": "text"
      },
      "source": [
        "## Export"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oviPW0uA4qQ2",
        "colab_type": "code",
        "outputId": "5c1ae0b5-a62f-4a43-d7be-54bf0a53cf01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        }
      },
      "source": [
        "!./notebook2script.py 02_fully_connected.ipynb"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: ./notebook2script.py: /usr/bin/env: bad interpreter: Permission denied\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxGsMmw84qQ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}